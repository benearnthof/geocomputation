Die präsentierten Verfahren zur Untersuchung räumlicher Daten zeigten sich als angemessen für die Erstellung von predictive Maps. Aus performancetechnischer Sicht konnte der SVM Ansatz am stärksten überzeugen, allerdings sind die erhaltenen Karten mit Vorsicht zu interpretieren. \\ In erster Linie ist die Auflösung der verwendeten Rasterdaten zu gering für akurate Prognosen, aber auch die räumliche Konstantheit der geschätzten Koeffizienten des Logit-Modells und das Finden eines optimalen Bufferradius zum Sampling von non-presence Punkten sind unter Umständen problematisch. Abgesehen davon stellte sich heraus, dass beide der zum Tuning der Modelle und Einschätzen der predictive performance dieser, angewendeten Resamplingverfahren nicht ideal sind, um für räumlich korrelierte Daten in einem großen Gebiet wie Bayern sinnvolle Ergebnisse zu produzieren.  
Um die Problematik der Bestimmung eines "optimalen" Bufferradius zu umgehen bieten sich Maximum-Entropy Verfahren \cite{phillips2006maximum} oder der Punktprozessanalyse  an, welche zur Habitatmodellierung ohne Nonpräsenzdaten herangezogen werden können.\\
Natürlich sollte auch nicht unerwähnt bleiben, dass der Rasterstack aus Daten der Moderne zusammengefügt wurde, welche im Allgemeinen nicht repräsentativ für die tatsächliche Habitatsituation in der Eisenzeit sind. (Main-Donau Kanal im Gewässernetz etc.) \\
Darüber hinaus ließe sich mittels Gaußprozess-Regression \cite{gaussprozess} oder ähnlichen Verfahren zur Interpolation diskreter, räumlich korrelierter Messdaten das manuelle Zusammentragen eines Referenzdatensatzes zur Erzeugung von Nonpräsenzdaten vermeiden um direkt auf Basis der von Fender bereitgestellten Daten predictive Maps zu generieren. \\
Abschließend war die Bearbeitung georeferenzierter Daten mit Techniken aus dem maschinellen Lernen ein ausgesprochen interessantes Problem. 